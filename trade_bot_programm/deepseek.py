"""
DeepSeek AI –∫–ª–∏–µ–Ω—Ç —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π reasoning —Ä–µ–∂–∏–º–∞ —á–µ—Ä–µ–∑ .env
"""

import os
from openai import AsyncOpenAI
from typing import Optional, Dict, List
from pathlib import Path


class DeepSeekClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DeepSeek API (—Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenAI SDK)"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        use_reasoning: Optional[bool] = None,
        base_url: str = "https://api.deepseek.com"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ DeepSeek

        Args:
            api_key: API –∫–ª—é—á (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ DEEPSEEK_API_KEY)
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ DEEPSEEK_MODEL)
            use_reasoning: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å reasoning (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ DEEPSEEK_REASONING)
            base_url: –ë–∞–∑–æ–≤—ã–π URL API
        """
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError("DEEPSEEK_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ .env")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –∏–∑ env –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.model = model or os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º reasoning –∏–∑ env
        reasoning_env = os.getenv("DEEPSEEK_REASONING", "false").lower()
        self.use_reasoning = use_reasoning if use_reasoning is not None else (reasoning_env in ["true", "1", "yes"])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å reasoning –º–æ–¥–µ–ª—å—é
        self.is_reasoning_model = "reasoner" in self.model.lower() or self.model == "deepseek-reasoner"

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ —Ä–µ–∂–∏–º reasoning –≤–∫–ª—é—á–µ–Ω –¥–ª—è non-reasoning –º–æ–¥–µ–ª–∏
        if self.use_reasoning and not self.is_reasoning_model:
            print(f"[DeepSeek] ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: DEEPSEEK_REASONING=true, –Ω–æ –º–æ–¥–µ–ª—å {self.model} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç reasoning")
            print(f"[DeepSeek] ‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DEEPSEEK_MODEL=deepseek-reasoner –¥–ª—è reasoning —Ä–µ–∂–∏–º–∞")
            print(f"[DeepSeek] üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫–ª—é—á–∞–µ–º reasoning —Ä–µ–∂–∏–º")
            self.use_reasoning = False

        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=base_url
        )

        self.prompts_cache: Dict[str, str] = {}

        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        print(f"[DeepSeek] ‚ïî{'‚ïê'*60}‚ïó")
        print(f"[DeepSeek] ‚ïë {'–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø DEEPSEEK':^60} ‚ïë")
        print(f"[DeepSeek] ‚ï†{'‚ïê'*60}‚ï£")
        print(f"[DeepSeek] ‚ïë –ú–æ–¥–µ–ª—å: {self.model:<49} ‚ïë")
        print(f"[DeepSeek] ‚ïë Reasoning –º–æ–¥–µ–ª—å: {'–î–∞' if self.is_reasoning_model else '–ù–µ—Ç':<43} ‚ïë")
        print(f"[DeepSeek] ‚ïë Reasoning —Ä–µ–∂–∏–º: {'‚úÖ –í–∫–ª—é—á–µ–Ω' if self.use_reasoning else '‚ùå –í—ã–∫–ª—é—á–µ–Ω':<44} ‚ïë")
        print(f"[DeepSeek] ‚ïë Base URL: {base_url:<47} ‚ïë")
        print(f"[DeepSeek] ‚ïö{'‚ïê'*60}‚ïù")

    def _load_prompt(self, prompt_file: str) -> str:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if prompt_file in self.prompts_cache:
            return self.prompts_cache[prompt_file]

        prompts_dir = Path(__file__).parent.parent / "prompts"
        prompt_path = prompts_dir / prompt_file

        if not prompt_path.exists():
            raise FileNotFoundError(f"–ü—Ä–æ–º–ø—Ç —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}")

        with open(prompt_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.prompts_cache[prompt_file] = content
        print(f"[DeepSeek] üìÑ –ü—Ä–æ–º–ø—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω: {prompt_file} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")

        return content

    async def select_pairs(
        self,
        pairs_data: List[Dict],
        max_pairs: Optional[int] = None,
        system_prompt_file: str = "prompt_select.txt",
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> List[str]:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä—ã –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö

        Args:
            pairs_data: –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö –æ –ø–∞—Ä–∞—Ö
            max_pairs: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞
            system_prompt_file: –§–∞–π–ª —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–∏–∑ .env AI_TEMPERATURE_SELECT –µ—Å–ª–∏ None)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (–∏–∑ .env AI_MAX_TOKENS_SELECT –µ—Å–ª–∏ None)

        Returns:
            –°–ø–∏—Å–æ–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤
        """
        try:
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ env
            if temperature is None:
                temperature = float(os.getenv("AI_TEMPERATURE_SELECT", "0.3"))
            if max_tokens is None:
                max_tokens = int(os.getenv("AI_MAX_TOKENS_SELECT", "2000"))

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self._load_prompt(system_prompt_file)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–∞—Ä–∞—Ö
            pairs_info = []
            for pair in pairs_data:
                info = (
                    f"–ü–∞—Ä–∞: {pair['ticker']}\n"
                    f"–°–∏–≥–Ω–∞–ª: {pair['signal_type']} ({pair['signal_strength']}%)\n"
                    f"–¶–µ–Ω–∞: ${pair['price']:.8f}\n"
                    f"–û–±—ä–µ–º 24—á: ${pair.get('volume_24h', 0):,.0f}\n"
                    f"–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: {pair.get('liquidity', 0):.1f}\n"
                )
                if pair.get('technical_data'):
                    info += f"–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:\n{pair['technical_data']}\n"
                pairs_info.append(info)

            pairs_text = "\n---\n".join(pairs_info)

            # –§–æ—Ä–º–∏—Ä—É–µ–º user –ø—Ä–æ–º–ø—Ç
            limit_text = f"–º–∞–∫—Å–∏–º—É–º {max_pairs} –ø–∞—Ä" if max_pairs else "–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"
            user_prompt = (
                f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ {len(pairs_data)} —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä –∏ –≤—ã–±–µ—Ä–∏ {limit_text} "
                f"—Å –Ω–∞–∏–ª—É—á—à–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏:\n\n{pairs_text}\n\n"
                f"–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: BTC, ETH, SOL)"
            )

            print(f"\n[DeepSeek] {'‚îÄ'*60}")
            print(f"[DeepSeek] üéØ STAGE 2: –í–´–ë–û–† –ü–ê–†")
            print(f"[DeepSeek] {'‚îÄ'*60}")
            print(f"[DeepSeek] üìä –ü–∞—Ä –Ω–∞ –∞–Ω–∞–ª–∏–∑: {len(pairs_data)}")
            print(f"[DeepSeek] üéöÔ∏è  –õ–∏–º–∏—Ç –≤—ã–±–æ—Ä–∞: {limit_text}")
            print(f"[DeepSeek] üìè –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(pairs_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"[DeepSeek] ü§ñ –ú–æ–¥–µ–ª—å: {self.model}")
            print(f"[DeepSeek] üå°Ô∏è  Temperature: {temperature}")
            print(f"[DeepSeek] üé´ Max tokens: {max_tokens}")
            print(f"[DeepSeek] üí≠ Reasoning: {'‚úÖ' if self.use_reasoning else '‚ùå'}")

            # –í—ã–∑—ã–≤–∞–µ–º API
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning –¥–ª—è reasoning –º–æ–¥–µ–ª–µ–π
            if self.use_reasoning and self.is_reasoning_model:
                if hasattr(response.choices[0].message, 'reasoning_content'):
                    reasoning = response.choices[0].message.reasoning_content
                    if reasoning:
                        print(f"\n[DeepSeek] {'='*60}")
                        print(f"[DeepSeek] üí≠ –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ú–û–î–ï–õ–ò (–ø–µ—Ä–≤—ã–µ 800 —Å–∏–º–≤–æ–ª–æ–≤):")
                        print(f"[DeepSeek] {'='*60}")
                        print(f"{reasoning[:800]}...")
                        print(f"[DeepSeek] {'='*60}\n")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            content = response.choices[0].message.content.strip()

            print(f"[DeepSeek] üìù –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(f"[DeepSeek]    {content[:200]}...")

            # –ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤
            selected = []
            for line in content.split('\n'):
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('//'):
                    continue

                # –ò—â–µ–º —Ç–∏–∫–µ—Ä—ã
                tokens = line.replace(',', ' ').split()
                for token in tokens:
                    token = token.strip().upper()
                    if 2 <= len(token) <= 10 and token.replace('USDT', '').replace('USD', '').isalnum():
                        clean_token = token.replace('USDT', '').replace('USD', '')
                        if clean_token and clean_token not in selected:
                            selected.append(clean_token)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç
            if max_pairs and len(selected) > max_pairs:
                selected = selected[:max_pairs]

            print(f"\n[DeepSeek] {'='*60}")
            print(f"[DeepSeek] ‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢: –í—ã–±—Ä–∞–Ω–æ {len(selected)} –ø–∞—Ä")
            if selected:
                print(f"[DeepSeek] üìã –°–ø–∏—Å–æ–∫: {', '.join(selected)}")
            print(f"[DeepSeek] {'='*60}\n")

            return selected

        except Exception as e:
            print(f"\n[DeepSeek] ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ø–∞—Ä: {e}")
            import traceback
            traceback.print_exc()
            return []

    async def analyze_pair(
        self,
        pair_data: Dict,
        analysis_prompt_file: str = "prompt_analyze.txt",
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–æ—Ä–≥–æ–≤—É—é –ø–∞—Ä—É

        Args:
            pair_data: –î–∞–Ω–Ω—ã–µ –æ –ø–∞—Ä–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_prompt_file: –§–∞–π–ª —Å –ø—Ä–æ–º–ø—Ç–æ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–∏–∑ .env AI_TEMPERATURE_ANALYZE –µ—Å–ª–∏ None)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (–∏–∑ .env AI_MAX_TOKENS_ANALYZE –µ—Å–ª–∏ None)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ env
            if temperature is None:
                temperature = float(os.getenv("AI_TEMPERATURE_ANALYZE", "0.7"))
            if max_tokens is None:
                max_tokens = int(os.getenv("AI_MAX_TOKENS_ANALYZE", "3000"))

            system_prompt = self._load_prompt(analysis_prompt_file)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–∞—Ä–µ
            pair_info = (
                f"–¢–∏–∫–µ—Ä: {pair_data['ticker']}\n"
                f"–¶–µ–Ω–∞: ${pair_data['price']:.8f}\n"
                f"–û–±—ä–µ–º 24—á: ${pair_data.get('volume_24h', 0):,.0f}\n"
            )

            if pair_data.get('technical_data'):
                pair_info += f"\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:\n{pair_data['technical_data']}\n"

            user_prompt = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é —Ç–æ—Ä–≥–æ–≤—É—é –ø–∞—Ä—É:\n\n{pair_info}"

            print(f"\n[DeepSeek] üî¨ –ê–Ω–∞–ª–∏–∑ –ø–∞—Ä—ã: {pair_data['ticker']}")
            print(f"[DeepSeek] üå°Ô∏è  Temperature: {temperature}, Max tokens: {max_tokens}")

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning
            if self.use_reasoning and self.is_reasoning_model:
                if hasattr(response.choices[0].message, 'reasoning_content'):
                    reasoning = response.choices[0].message.reasoning_content
                    if reasoning:
                        print(f"[DeepSeek] üí≠ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤):")
                        print(f"      {reasoning[:300]}...")

            content = response.choices[0].message.content.strip()

            print(f"[DeepSeek] ‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {pair_data['ticker']}")

            return {
                'ticker': pair_data['ticker'],
                'analysis': content,
                'model': self.model,
                'reasoning_used': self.use_reasoning and self.is_reasoning_model
            }

        except Exception as e:
            print(f"[DeepSeek] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {pair_data.get('ticker', 'unknown')}: {e}")
            return None

    async def chat(
        self,
        messages: List[Dict[str, str]],
        max_tokens: int = 2000,
        temperature: float = 0.7
    ) -> str:
        """
        –û–±—â–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —á–∞—Ç–∞ —Å DeepSeek

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º reasoning
            if self.use_reasoning and self.is_reasoning_model:
                if hasattr(response.choices[0].message, 'reasoning_content'):
                    reasoning = response.choices[0].message.reasoning_content
                    if reasoning:
                        print(f"[DeepSeek] üí≠ –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:")
                        print(f"      {reasoning[:500]}...")

            return response.choices[0].message.content.strip()

        except Exception as e:
            print(f"[DeepSeek] ‚ùå –û—à–∏–±–∫–∞ —á–∞—Ç–∞: {e}")
            raise